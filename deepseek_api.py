import time
import pandas as pd
import os
from openai import OpenAI

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key="your api_key", base_url="https://api.deepseek.com")

# åŠ è½½ CSV æ–‡ä»¶
csv_file_path = "æ–°é—»åˆ‡å‰²_4.csv"  # æ›¿æ¢ä¸ºä½ çš„ CSV æ–‡ä»¶è·¯å¾„
df = pd.read_csv(csv_file_path)

# æ£€æŸ¥åˆ—åæ˜¯å¦æ­£ç¡®
expected_columns = ["title", "link", "content"]
for col in expected_columns:
    if col not in df.columns:
        raise ValueError(f"CSVæ–‡ä»¶ä¸­ç¼ºå°‘å¿…éœ€çš„åˆ—: {col}")

# æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„åˆ—
for col in ["ç²—é¢—ç²’åˆ†ç±»", "ç»†é¢—ç²’åˆ†ç±»", "åŸå› ", "å¤šåˆ†ç±»"]:
    if col not in df.columns:
        df[col] = ""


# æç¤ºè¯
PROMPT = """

"""
# å®šä¹‰è°ƒç”¨ DeepSeek-R1 çš„å‡½æ•° (ä¿æŒä¸å˜)
def analyze_news(title, content):
    """è°ƒç”¨ DeepSeek API åˆ†ææ–°é—»æ ‡é¢˜å…šç±»å‹"""
    try:
        response = client.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {"role": "system", "content": PROMPT},
                {"role": "user", "content": f"è¯·åˆ†æä»¥ä¸‹æ–°é—»çš„æ ‡é¢˜å…šç±»å‹ï¼š\næ ‡é¢˜ï¼š{title}\nå†…å®¹ï¼š{content}"},
            ],
            stream=False
        )

        print("Raw Response:", response)  # æ‰“å° API å“åº”ï¼ˆè°ƒè¯•ç”¨ï¼‰

        if not response or not response.choices:
            print(" API è¿”å›ç©ºï¼")
            return "ç²—é¢—ç²’åˆ†ç±»ï¼šæœªçŸ¥\nç»†é¢—ç²’åˆ†ç±»ï¼šæœªçŸ¥\nåŸå› ï¼šAPI è¿”å›ç©º\nå¤šåˆ†ç±»ï¼šæœªçŸ¥"

        return response.choices[0].message.content

    except Exception as e:
        print(f" API è°ƒç”¨å¤±è´¥: {e}")
        time.sleep(5)  # API å¤±è´¥æ—¶ç­‰å¾… 5 ç§’å†è¯•
        return "ç²—é¢—ç²’åˆ†ç±»ï¼šæœªçŸ¥\nç»†é¢—ç²’åˆ†ç±»ï¼šæœªçŸ¥\nåŸå› ï¼šAPI è°ƒç”¨å¼‚å¸¸\nå¤šåˆ†ç±»ï¼šæœªçŸ¥"

# è¾“å‡º CSV æ–‡ä»¶è·¯å¾„
output_csv_file_path = "æƒ…æ„Ÿ1.csv"

# å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå…ˆå†™å…¥è¡¨å¤´
if not os.path.exists(output_csv_file_path):
    df.to_csv(output_csv_file_path, index=False, mode="w", header=True, encoding="utf_8_sig")

# éå†æ‰€æœ‰è¡Œæ•°æ®
for index, row in df.iterrows():
    title = row["title"]  # ä¿®æ”¹ä¸º Title
    content = row["content"]  # ä¿®æ”¹ä¸º Content
    url = row["link"]  # æ–°å¢URLå˜é‡ï¼Œè™½ç„¶å½“å‰ä»£ç æœªä½¿ç”¨

    print(f" åˆ†æç¬¬ {index+1} æ¡æ–°é—»...")
    print(f" URL: {url}")  # æ‰“å°URLä¿¡æ¯ï¼ˆå¯é€‰ï¼‰

    # è·³è¿‡ç©ºæ•°æ®
    if pd.isna(title) or pd.isna(content):
        print(f" ç¬¬ {index+1} æ¡æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ï¼")
        continue  

    # é™åˆ¶ API é€Ÿç‡
    time.sleep(1)

    result = analyze_news(title, content)

    # è§£æ API ç»“æœ
    try:
        lines = [line.strip() for line in result.split("\n") if line.strip()]
        result_dict = {}
        for line in lines:
            if "ï¼š" in line:
                key, value = line.split("ï¼š", 1)
                result_dict[key.strip()] = value.strip()
        
        coarse_grained = result_dict.get("ç²—é¢—ç²’åˆ†ç±»", "æœªçŸ¥")
        fine_grained = result_dict.get("ç»†é¢—ç²’åˆ†ç±»", "æœªçŸ¥")
        reason = result_dict.get("åŸå› ", "æœªçŸ¥")
        multi_class = result_dict.get("å¤šåˆ†ç±»", "æœªçŸ¥")
        
    except Exception as e:
        print(f" è§£æç»“æœå‡ºé”™: {e}")
        coarse_grained, fine_grained, reason, multi_class = "æœªçŸ¥", "æœªçŸ¥", "è§£æå‡ºé”™", "æœªçŸ¥"

    print(f" æ ‡é¢˜: {title}")
    print(f" ç²—é¢—ç²’åˆ†ç±»: {coarse_grained}")
    print(f" ç»†é¢—ç²’åˆ†ç±»: {fine_grained}")
    print(f" åŸå› : {reason}")
    print(f" å¤šåˆ†ç±»: {multi_class}")
    print("------")

    # æ›´æ–° DataFrame
    df.at[index, "ç²—é¢—ç²’åˆ†ç±»"] = coarse_grained
    df.at[index, "ç»†é¢—ç²’åˆ†ç±»"] = fine_grained
    df.at[index, "åŸå› "] = reason
    df.at[index, "å¤šåˆ†ç±»"] = multi_class

    # è¿½åŠ å†™å…¥ CSV
    with open(output_csv_file_path, "a", encoding="utf_8_sig", newline="") as f:
        df.iloc[[index]].to_csv(f, index=False, mode="a", header=False)
        f.flush()

print(f"ğŸ‰ ç»“æœå·²ä¿å­˜åˆ°: {output_csv_file_path}")